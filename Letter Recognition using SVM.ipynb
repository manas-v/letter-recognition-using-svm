{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing SVM Kernels performance using Letter Recognition Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective - Letter Recognition using SVM\n",
    "\n",
    "The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli. Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "\n",
    "The Dataset was obtained from the UCI Machine Learning Repository(https://archive.ics.uci.edu/ml/datasets/letter+recognition)\n",
    "\n",
    "Each row in the data set represents an image of a handwritten alphabet, as shown in figure 1(A). Using some basic image processing, the images are converted into m X n pixels (figure 1(B)), where m and n depend on the size and resolution of the original image. Each pixel contains numeric values, with higher values denoting the presence of dense 'ink'. In the pixels where nothing is written, the pixel value is 0.\n",
    "\n",
    "A pixel is called 'on' if it contains to a positive numeric value, else it is called 'off'.\n",
    "\n",
    "Using the pixelated images, 16 features are derived for each image, such as the width of the box, the ratio of the mean variance of x divided by the width of the box, etc.\n",
    "\n",
    "![title](letter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Information:\n",
    "\n",
    "1. lettr capital letter (26 values from A to Z)\n",
    "2. x-box horizontal position of box (integer)\n",
    "3. y-box vertical position of box (integer)\n",
    "4. width width of box (integer)\n",
    "5. high height of box (integer)\n",
    "6. onpix total # on pixels (integer)\n",
    "7. x-bar mean x of on pixels in box (integer)\n",
    "8. y-bar mean y of on pixels in box (integer)\n",
    "9. x2bar mean x variance (integer)\n",
    "10. y2bar mean y variance (integer)\n",
    "11. xybar mean x y correlation (integer)\n",
    "12. x2ybr mean of x * x * y (integer)\n",
    "13. xy2br mean of x * y * y (integer)\n",
    "14. x-ege mean edge count left to right (integer)\n",
    "15. xegvy correlation of x-ege with y (integer)\n",
    "16. y-ege mean edge count bottom to top (integer)\n",
    "17. yegvx correlation of y-ege with x (integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
       "0      T      2      8       3       5       1      8     13      0       6   \n",
       "1      I      5     12       3       7       2     10      5      5       4   \n",
       "2      D      4     11       6       8       6     10      6      2       6   \n",
       "3      N      7     11       6       6       3      5      9      4       6   \n",
       "4      G      2      1       3       1       1      8      6      6       6   \n",
       "\n",
       "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0       6      10       8       0       8       0       8  \n",
       "1      13       3       9       2       8       4      10  \n",
       "2      10       3       7       3       7       3       9  \n",
       "3       4       4      10       6      10       2       8  \n",
       "4       6       5       9       1       7       5      10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('letter-recognition.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              xbox          ybox         width        height        onpix   \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "              xbar          ybar          x2bar        y2bar         xybar   \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar        xedge         xedgey        yedge   \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Visualization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3.337136</td>\n",
       "      <td>6.975919</td>\n",
       "      <td>5.128010</td>\n",
       "      <td>5.178707</td>\n",
       "      <td>2.991128</td>\n",
       "      <td>8.851711</td>\n",
       "      <td>3.631179</td>\n",
       "      <td>2.755387</td>\n",
       "      <td>2.043093</td>\n",
       "      <td>7.802281</td>\n",
       "      <td>2.338403</td>\n",
       "      <td>8.465146</td>\n",
       "      <td>2.771863</td>\n",
       "      <td>6.321926</td>\n",
       "      <td>2.875792</td>\n",
       "      <td>7.468948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>3.985640</td>\n",
       "      <td>6.962141</td>\n",
       "      <td>5.088773</td>\n",
       "      <td>5.169713</td>\n",
       "      <td>4.596606</td>\n",
       "      <td>7.671018</td>\n",
       "      <td>7.062663</td>\n",
       "      <td>5.366841</td>\n",
       "      <td>5.571802</td>\n",
       "      <td>7.954308</td>\n",
       "      <td>5.506527</td>\n",
       "      <td>6.652742</td>\n",
       "      <td>3.117493</td>\n",
       "      <td>7.919060</td>\n",
       "      <td>6.612272</td>\n",
       "      <td>9.100522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>4.031250</td>\n",
       "      <td>7.063859</td>\n",
       "      <td>4.701087</td>\n",
       "      <td>5.296196</td>\n",
       "      <td>2.775815</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>7.627717</td>\n",
       "      <td>5.927989</td>\n",
       "      <td>7.177989</td>\n",
       "      <td>8.773098</td>\n",
       "      <td>7.494565</td>\n",
       "      <td>11.947011</td>\n",
       "      <td>1.991848</td>\n",
       "      <td>8.876359</td>\n",
       "      <td>4.080163</td>\n",
       "      <td>8.555707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>4.023602</td>\n",
       "      <td>7.244720</td>\n",
       "      <td>5.170186</td>\n",
       "      <td>5.288199</td>\n",
       "      <td>4.026087</td>\n",
       "      <td>7.539130</td>\n",
       "      <td>6.806211</td>\n",
       "      <td>5.921739</td>\n",
       "      <td>6.508075</td>\n",
       "      <td>8.166460</td>\n",
       "      <td>5.111801</td>\n",
       "      <td>5.750311</td>\n",
       "      <td>3.365217</td>\n",
       "      <td>7.813665</td>\n",
       "      <td>3.971429</td>\n",
       "      <td>7.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>3.727865</td>\n",
       "      <td>6.944010</td>\n",
       "      <td>4.756510</td>\n",
       "      <td>5.201823</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>5.966146</td>\n",
       "      <td>7.352865</td>\n",
       "      <td>4.223958</td>\n",
       "      <td>7.585938</td>\n",
       "      <td>8.507812</td>\n",
       "      <td>6.242188</td>\n",
       "      <td>10.341146</td>\n",
       "      <td>2.127604</td>\n",
       "      <td>8.298177</td>\n",
       "      <td>6.022135</td>\n",
       "      <td>8.506510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>3.832258</td>\n",
       "      <td>7.009032</td>\n",
       "      <td>4.898065</td>\n",
       "      <td>5.209032</td>\n",
       "      <td>3.178065</td>\n",
       "      <td>4.913548</td>\n",
       "      <td>10.454194</td>\n",
       "      <td>3.476129</td>\n",
       "      <td>4.886452</td>\n",
       "      <td>11.242581</td>\n",
       "      <td>7.830968</td>\n",
       "      <td>5.723871</td>\n",
       "      <td>1.736774</td>\n",
       "      <td>9.117419</td>\n",
       "      <td>3.321290</td>\n",
       "      <td>6.712258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>4.086675</td>\n",
       "      <td>6.988357</td>\n",
       "      <td>4.988357</td>\n",
       "      <td>5.282018</td>\n",
       "      <td>3.566624</td>\n",
       "      <td>6.866753</td>\n",
       "      <td>6.586028</td>\n",
       "      <td>5.966365</td>\n",
       "      <td>5.337646</td>\n",
       "      <td>7.429495</td>\n",
       "      <td>6.157827</td>\n",
       "      <td>9.586028</td>\n",
       "      <td>2.833118</td>\n",
       "      <td>8.369987</td>\n",
       "      <td>5.146184</td>\n",
       "      <td>9.216041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>4.331063</td>\n",
       "      <td>6.844687</td>\n",
       "      <td>5.784741</td>\n",
       "      <td>5.193460</td>\n",
       "      <td>4.253406</td>\n",
       "      <td>7.344687</td>\n",
       "      <td>7.320163</td>\n",
       "      <td>6.702997</td>\n",
       "      <td>4.280654</td>\n",
       "      <td>8.044959</td>\n",
       "      <td>5.899183</td>\n",
       "      <td>7.801090</td>\n",
       "      <td>3.862398</td>\n",
       "      <td>8.047684</td>\n",
       "      <td>3.095368</td>\n",
       "      <td>7.858311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>2.270199</td>\n",
       "      <td>6.980132</td>\n",
       "      <td>2.631788</td>\n",
       "      <td>5.209272</td>\n",
       "      <td>1.825166</td>\n",
       "      <td>7.458278</td>\n",
       "      <td>7.035762</td>\n",
       "      <td>1.940397</td>\n",
       "      <td>5.973510</td>\n",
       "      <td>9.476821</td>\n",
       "      <td>5.797351</td>\n",
       "      <td>7.649007</td>\n",
       "      <td>0.537748</td>\n",
       "      <td>8.066225</td>\n",
       "      <td>2.141722</td>\n",
       "      <td>7.931126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>2.970549</td>\n",
       "      <td>6.799197</td>\n",
       "      <td>3.994645</td>\n",
       "      <td>5.614458</td>\n",
       "      <td>2.315930</td>\n",
       "      <td>9.665328</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>3.921017</td>\n",
       "      <td>5.087015</td>\n",
       "      <td>12.168675</td>\n",
       "      <td>4.663989</td>\n",
       "      <td>8.958501</td>\n",
       "      <td>1.105756</td>\n",
       "      <td>6.927711</td>\n",
       "      <td>1.926372</td>\n",
       "      <td>7.416332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>4.510149</td>\n",
       "      <td>7.320704</td>\n",
       "      <td>5.945873</td>\n",
       "      <td>5.373478</td>\n",
       "      <td>3.981055</td>\n",
       "      <td>5.592693</td>\n",
       "      <td>7.070365</td>\n",
       "      <td>3.822733</td>\n",
       "      <td>5.327470</td>\n",
       "      <td>8.217862</td>\n",
       "      <td>6.205683</td>\n",
       "      <td>9.833559</td>\n",
       "      <td>4.029770</td>\n",
       "      <td>7.699594</td>\n",
       "      <td>4.081191</td>\n",
       "      <td>8.818674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>3.417871</td>\n",
       "      <td>7.128778</td>\n",
       "      <td>4.356110</td>\n",
       "      <td>5.296978</td>\n",
       "      <td>2.649146</td>\n",
       "      <td>4.800263</td>\n",
       "      <td>3.592641</td>\n",
       "      <td>3.450723</td>\n",
       "      <td>6.642576</td>\n",
       "      <td>4.959264</td>\n",
       "      <td>2.545335</td>\n",
       "      <td>8.165572</td>\n",
       "      <td>1.106439</td>\n",
       "      <td>7.391590</td>\n",
       "      <td>2.480946</td>\n",
       "      <td>7.651774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4.895202</td>\n",
       "      <td>6.954545</td>\n",
       "      <td>6.637626</td>\n",
       "      <td>5.275253</td>\n",
       "      <td>5.267677</td>\n",
       "      <td>7.641414</td>\n",
       "      <td>6.407828</td>\n",
       "      <td>6.041667</td>\n",
       "      <td>3.270202</td>\n",
       "      <td>7.478535</td>\n",
       "      <td>6.813131</td>\n",
       "      <td>8.165404</td>\n",
       "      <td>8.154040</td>\n",
       "      <td>6.135101</td>\n",
       "      <td>2.107323</td>\n",
       "      <td>7.518939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>4.508301</td>\n",
       "      <td>7.173691</td>\n",
       "      <td>5.803321</td>\n",
       "      <td>5.346105</td>\n",
       "      <td>3.564496</td>\n",
       "      <td>7.012771</td>\n",
       "      <td>7.952746</td>\n",
       "      <td>6.629630</td>\n",
       "      <td>3.735632</td>\n",
       "      <td>7.372925</td>\n",
       "      <td>5.906769</td>\n",
       "      <td>7.328225</td>\n",
       "      <td>5.448276</td>\n",
       "      <td>8.446999</td>\n",
       "      <td>1.458493</td>\n",
       "      <td>7.043423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>4.114210</td>\n",
       "      <td>7.124834</td>\n",
       "      <td>4.881806</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.503320</td>\n",
       "      <td>7.341301</td>\n",
       "      <td>6.965471</td>\n",
       "      <td>7.140770</td>\n",
       "      <td>4.791501</td>\n",
       "      <td>7.905710</td>\n",
       "      <td>5.868526</td>\n",
       "      <td>8.013280</td>\n",
       "      <td>3.381142</td>\n",
       "      <td>8.095618</td>\n",
       "      <td>3.630810</td>\n",
       "      <td>7.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>4.268991</td>\n",
       "      <td>7.219178</td>\n",
       "      <td>5.298879</td>\n",
       "      <td>5.524284</td>\n",
       "      <td>3.735990</td>\n",
       "      <td>6.219178</td>\n",
       "      <td>9.955168</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>3.460772</td>\n",
       "      <td>10.435866</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4.191781</td>\n",
       "      <td>2.186800</td>\n",
       "      <td>9.792030</td>\n",
       "      <td>3.879203</td>\n",
       "      <td>7.704857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>4.043423</td>\n",
       "      <td>6.404853</td>\n",
       "      <td>4.914432</td>\n",
       "      <td>6.408685</td>\n",
       "      <td>4.136654</td>\n",
       "      <td>8.160920</td>\n",
       "      <td>6.808429</td>\n",
       "      <td>6.080460</td>\n",
       "      <td>3.908046</td>\n",
       "      <td>6.802043</td>\n",
       "      <td>6.348659</td>\n",
       "      <td>9.229885</td>\n",
       "      <td>3.141762</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>5.356322</td>\n",
       "      <td>8.945083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>4.069921</td>\n",
       "      <td>7.042216</td>\n",
       "      <td>5.226913</td>\n",
       "      <td>5.220317</td>\n",
       "      <td>4.187335</td>\n",
       "      <td>7.147757</td>\n",
       "      <td>8.122691</td>\n",
       "      <td>5.373351</td>\n",
       "      <td>4.622691</td>\n",
       "      <td>7.691293</td>\n",
       "      <td>4.320580</td>\n",
       "      <td>7.613456</td>\n",
       "      <td>3.624011</td>\n",
       "      <td>6.955145</td>\n",
       "      <td>5.126649</td>\n",
       "      <td>9.470976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>4.101604</td>\n",
       "      <td>7.441176</td>\n",
       "      <td>5.044118</td>\n",
       "      <td>5.450535</td>\n",
       "      <td>3.486631</td>\n",
       "      <td>7.811497</td>\n",
       "      <td>6.945187</td>\n",
       "      <td>4.596257</td>\n",
       "      <td>6.295455</td>\n",
       "      <td>8.167112</td>\n",
       "      <td>5.606952</td>\n",
       "      <td>7.576203</td>\n",
       "      <td>1.877005</td>\n",
       "      <td>8.200535</td>\n",
       "      <td>7.037433</td>\n",
       "      <td>7.871658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>3.996231</td>\n",
       "      <td>7.125628</td>\n",
       "      <td>4.820352</td>\n",
       "      <td>5.193467</td>\n",
       "      <td>2.858040</td>\n",
       "      <td>6.428392</td>\n",
       "      <td>11.369347</td>\n",
       "      <td>2.556533</td>\n",
       "      <td>6.515075</td>\n",
       "      <td>8.820352</td>\n",
       "      <td>9.316583</td>\n",
       "      <td>6.707286</td>\n",
       "      <td>1.600503</td>\n",
       "      <td>9.685930</td>\n",
       "      <td>2.277638</td>\n",
       "      <td>6.300251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>4.581796</td>\n",
       "      <td>7.070111</td>\n",
       "      <td>5.387454</td>\n",
       "      <td>5.242312</td>\n",
       "      <td>3.325953</td>\n",
       "      <td>6.116851</td>\n",
       "      <td>6.936039</td>\n",
       "      <td>7.282903</td>\n",
       "      <td>5.937269</td>\n",
       "      <td>7.548585</td>\n",
       "      <td>9.690037</td>\n",
       "      <td>8.528905</td>\n",
       "      <td>3.789668</td>\n",
       "      <td>8.799508</td>\n",
       "      <td>1.740467</td>\n",
       "      <td>6.906519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>4.270942</td>\n",
       "      <td>7.324607</td>\n",
       "      <td>5.332461</td>\n",
       "      <td>5.391361</td>\n",
       "      <td>2.815445</td>\n",
       "      <td>6.056283</td>\n",
       "      <td>10.136126</td>\n",
       "      <td>3.484293</td>\n",
       "      <td>3.024869</td>\n",
       "      <td>7.818063</td>\n",
       "      <td>10.942408</td>\n",
       "      <td>7.650524</td>\n",
       "      <td>3.286649</td>\n",
       "      <td>10.244764</td>\n",
       "      <td>1.595550</td>\n",
       "      <td>7.801047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>5.168883</td>\n",
       "      <td>7.156915</td>\n",
       "      <td>6.486702</td>\n",
       "      <td>5.343085</td>\n",
       "      <td>4.851064</td>\n",
       "      <td>6.078457</td>\n",
       "      <td>9.214096</td>\n",
       "      <td>3.488032</td>\n",
       "      <td>2.226064</td>\n",
       "      <td>7.574468</td>\n",
       "      <td>8.441489</td>\n",
       "      <td>7.801862</td>\n",
       "      <td>7.597074</td>\n",
       "      <td>10.375000</td>\n",
       "      <td>1.594415</td>\n",
       "      <td>7.142287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>4.069886</td>\n",
       "      <td>7.149936</td>\n",
       "      <td>5.651842</td>\n",
       "      <td>5.268107</td>\n",
       "      <td>3.213469</td>\n",
       "      <td>7.252859</td>\n",
       "      <td>7.171537</td>\n",
       "      <td>2.678526</td>\n",
       "      <td>6.795426</td>\n",
       "      <td>7.972046</td>\n",
       "      <td>6.161372</td>\n",
       "      <td>7.941550</td>\n",
       "      <td>2.942821</td>\n",
       "      <td>8.153748</td>\n",
       "      <td>4.842440</td>\n",
       "      <td>7.656925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>4.181934</td>\n",
       "      <td>6.706107</td>\n",
       "      <td>5.250636</td>\n",
       "      <td>5.736641</td>\n",
       "      <td>3.057252</td>\n",
       "      <td>6.436387</td>\n",
       "      <td>9.496183</td>\n",
       "      <td>2.599237</td>\n",
       "      <td>4.729008</td>\n",
       "      <td>7.898219</td>\n",
       "      <td>10.547074</td>\n",
       "      <td>7.118321</td>\n",
       "      <td>2.131043</td>\n",
       "      <td>10.610687</td>\n",
       "      <td>2.774809</td>\n",
       "      <td>6.354962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>3.737057</td>\n",
       "      <td>6.764305</td>\n",
       "      <td>4.878747</td>\n",
       "      <td>5.634877</td>\n",
       "      <td>3.250681</td>\n",
       "      <td>7.525886</td>\n",
       "      <td>7.125341</td>\n",
       "      <td>3.430518</td>\n",
       "      <td>9.196185</td>\n",
       "      <td>9.224796</td>\n",
       "      <td>5.835150</td>\n",
       "      <td>7.930518</td>\n",
       "      <td>1.237057</td>\n",
       "      <td>8.025886</td>\n",
       "      <td>7.152589</td>\n",
       "      <td>7.614441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width     height    onpix      xbar       ybar   \\\n",
       "letter                                                                          \n",
       "A       3.337136  6.975919  5.128010  5.178707  2.991128  8.851711   3.631179   \n",
       "B       3.985640  6.962141  5.088773  5.169713  4.596606  7.671018   7.062663   \n",
       "C       4.031250  7.063859  4.701087  5.296196  2.775815  5.437500   7.627717   \n",
       "D       4.023602  7.244720  5.170186  5.288199  4.026087  7.539130   6.806211   \n",
       "E       3.727865  6.944010  4.756510  5.201823  3.679688  5.966146   7.352865   \n",
       "F       3.832258  7.009032  4.898065  5.209032  3.178065  4.913548  10.454194   \n",
       "G       4.086675  6.988357  4.988357  5.282018  3.566624  6.866753   6.586028   \n",
       "H       4.331063  6.844687  5.784741  5.193460  4.253406  7.344687   7.320163   \n",
       "I       2.270199  6.980132  2.631788  5.209272  1.825166  7.458278   7.035762   \n",
       "J       2.970549  6.799197  3.994645  5.614458  2.315930  9.665328   5.666667   \n",
       "K       4.510149  7.320704  5.945873  5.373478  3.981055  5.592693   7.070365   \n",
       "L       3.417871  7.128778  4.356110  5.296978  2.649146  4.800263   3.592641   \n",
       "M       4.895202  6.954545  6.637626  5.275253  5.267677  7.641414   6.407828   \n",
       "N       4.508301  7.173691  5.803321  5.346105  3.564496  7.012771   7.952746   \n",
       "O       4.114210  7.124834  4.881806  5.333333  3.503320  7.341301   6.965471   \n",
       "P       4.268991  7.219178  5.298879  5.524284  3.735990  6.219178   9.955168   \n",
       "Q       4.043423  6.404853  4.914432  6.408685  4.136654  8.160920   6.808429   \n",
       "R       4.069921  7.042216  5.226913  5.220317  4.187335  7.147757   8.122691   \n",
       "S       4.101604  7.441176  5.044118  5.450535  3.486631  7.811497   6.945187   \n",
       "T       3.996231  7.125628  4.820352  5.193467  2.858040  6.428392  11.369347   \n",
       "U       4.581796  7.070111  5.387454  5.242312  3.325953  6.116851   6.936039   \n",
       "V       4.270942  7.324607  5.332461  5.391361  2.815445  6.056283  10.136126   \n",
       "W       5.168883  7.156915  6.486702  5.343085  4.851064  6.078457   9.214096   \n",
       "X       4.069886  7.149936  5.651842  5.268107  3.213469  7.252859   7.171537   \n",
       "Y       4.181934  6.706107  5.250636  5.736641  3.057252  6.436387   9.496183   \n",
       "Z       3.737057  6.764305  4.878747  5.634877  3.250681  7.525886   7.125341   \n",
       "\n",
       "           x2bar    y2bar      xybar      x2ybar     xy2bar    xedge   \\\n",
       "letter                                                                  \n",
       "A       2.755387  2.043093   7.802281   2.338403   8.465146  2.771863   \n",
       "B       5.366841  5.571802   7.954308   5.506527   6.652742  3.117493   \n",
       "C       5.927989  7.177989   8.773098   7.494565  11.947011  1.991848   \n",
       "D       5.921739  6.508075   8.166460   5.111801   5.750311  3.365217   \n",
       "E       4.223958  7.585938   8.507812   6.242188  10.341146  2.127604   \n",
       "F       3.476129  4.886452  11.242581   7.830968   5.723871  1.736774   \n",
       "G       5.966365  5.337646   7.429495   6.157827   9.586028  2.833118   \n",
       "H       6.702997  4.280654   8.044959   5.899183   7.801090  3.862398   \n",
       "I       1.940397  5.973510   9.476821   5.797351   7.649007  0.537748   \n",
       "J       3.921017  5.087015  12.168675   4.663989   8.958501  1.105756   \n",
       "K       3.822733  5.327470   8.217862   6.205683   9.833559  4.029770   \n",
       "L       3.450723  6.642576   4.959264   2.545335   8.165572  1.106439   \n",
       "M       6.041667  3.270202   7.478535   6.813131   8.165404  8.154040   \n",
       "N       6.629630  3.735632   7.372925   5.906769   7.328225  5.448276   \n",
       "O       7.140770  4.791501   7.905710   5.868526   8.013280  3.381142   \n",
       "P       5.363636  3.460772  10.435866   5.909091   4.191781  2.186800   \n",
       "Q       6.080460  3.908046   6.802043   6.348659   9.229885  3.141762   \n",
       "R       5.373351  4.622691   7.691293   4.320580   7.613456  3.624011   \n",
       "S       4.596257  6.295455   8.167112   5.606952   7.576203  1.877005   \n",
       "T       2.556533  6.515075   8.820352   9.316583   6.707286  1.600503   \n",
       "U       7.282903  5.937269   7.548585   9.690037   8.528905  3.789668   \n",
       "V       3.484293  3.024869   7.818063  10.942408   7.650524  3.286649   \n",
       "W       3.488032  2.226064   7.574468   8.441489   7.801862  7.597074   \n",
       "X       2.678526  6.795426   7.972046   6.161372   7.941550  2.942821   \n",
       "Y       2.599237  4.729008   7.898219  10.547074   7.118321  2.131043   \n",
       "Z       3.430518  9.196185   9.224796   5.835150   7.930518  1.237057   \n",
       "\n",
       "           xedgey    yedge     yedgex  \n",
       "letter                                 \n",
       "A        6.321926  2.875792  7.468948  \n",
       "B        7.919060  6.612272  9.100522  \n",
       "C        8.876359  4.080163  8.555707  \n",
       "D        7.813665  3.971429  7.628571  \n",
       "E        8.298177  6.022135  8.506510  \n",
       "F        9.117419  3.321290  6.712258  \n",
       "G        8.369987  5.146184  9.216041  \n",
       "H        8.047684  3.095368  7.858311  \n",
       "I        8.066225  2.141722  7.931126  \n",
       "J        6.927711  1.926372  7.416332  \n",
       "K        7.699594  4.081191  8.818674  \n",
       "L        7.391590  2.480946  7.651774  \n",
       "M        6.135101  2.107323  7.518939  \n",
       "N        8.446999  1.458493  7.043423  \n",
       "O        8.095618  3.630810  7.872510  \n",
       "P        9.792030  3.879203  7.704857  \n",
       "Q        8.333333  5.356322  8.945083  \n",
       "R        6.955145  5.126649  9.470976  \n",
       "S        8.200535  7.037433  7.871658  \n",
       "T        9.685930  2.277638  6.300251  \n",
       "U        8.799508  1.740467  6.906519  \n",
       "V       10.244764  1.595550  7.801047  \n",
       "W       10.375000  1.594415  7.142287  \n",
       "X        8.153748  4.842440  7.656925  \n",
       "Y       10.610687  2.774809  6.354962  \n",
       "Z        8.025886  7.152589  7.614441  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average features of all letters\n",
    "\n",
    "df_means = df.groupby('letter').mean()\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "#Ordered Letters\n",
    "\n",
    "order = list(np.sort(df_means.index.unique()))\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x228f8434280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting average features of all letters\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df_means.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   xybar   \\\n",
       "0      2      8       3       5       1      8     13      0       6       6   \n",
       "1      5     12       3       7       2     10      5      5       4      13   \n",
       "2      4     11       6       8       6     10      6      2       6      10   \n",
       "3      7     11       6       6       3      5      9      4       6       4   \n",
       "4      2      1       3       1       1      8      6      6       6       6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0      10       8       0       8       0       8  \n",
       "1       3       9       2       8       4      10  \n",
       "2       3       7       3       7       3       9  \n",
       "3       4      10       6      10       2       8  \n",
       "4       5       9       1       7       5      10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input Data\n",
    "\n",
    "X = df.drop('letter', axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    T\n",
       "1    I\n",
       "2    D\n",
       "3    N\n",
       "4    G\n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target Column\n",
    "\n",
    "y = df['letter']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into train-test\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.75,test_size=0.25,random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "Support Vector Classifier or SVC is capable of classification using multiple kernels (different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names =  ['Kernel Name', 'Accuracy']   \n",
    "acc  = pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuation(name, y_test, y_pred):\n",
    "    \n",
    "    #Model Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of \"+ name + \" is: \"+ str(accuracy))\n",
    "    \n",
    "    acc.loc[len(acc.index)] = [name, accuracy]  \n",
    "    \n",
    "    #Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cnf = metrics.confusion_matrix(y_true = y_test,y_pred = y_pred)\n",
    "    return(cnf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification using inbuilt Kernels\n",
    "\n",
    "SVM provides four inbuilt kernels for classification: linear, poly, rbf, sigmoid ('rbf' as default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_linear is: 0.8496\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[195,   0,   0,   0,   0,   0,   2,   0,   0,   0,   2,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0],\n",
       "       [  1, 157,   0,   3,   2,   0,   3,   1,   1,   0,   1,   0,   0,\n",
       "          1,   0,   1,   0,  11,   3,   0,   0,   1,   0,   1,   0,   0],\n",
       "       [  0,   0, 141,   0,   7,   0,   5,   1,   0,   0,   3,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   1,   2,   0,   0,   1,   0,   0],\n",
       "       [  3,  13,   0, 172,   0,   0,   0,   4,   0,   1,   2,   0,   0,\n",
       "          3,   4,   2,   0,   3,   0,   1,   3,   0,   0,   0,   0,   0],\n",
       "       [  0,   2,   1,   0, 164,   2,   8,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   1,   3,   3,   3,   5,   0,   0,   0,   2,   0,   0],\n",
       "       [  0,   2,   0,   2,   6, 179,   2,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   2,   0,   0,   5,   7,   0,   0,   0,   0,   1,   0],\n",
       "       [  1,   0,   9,   5,   3,   3, 144,   0,   0,   0,   4,   1,   1,\n",
       "          0,   1,   0,   9,   3,  10,   0,   1,   3,   0,   0,   0,   0],\n",
       "       [  0,   2,   2,   8,   0,   2,   1, 123,   0,   0,   9,   0,   0,\n",
       "          1,   8,   2,   2,  15,   0,   0,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   1,   4,   0,   2,   1,   0, 167,   2,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   2],\n",
       "       [  2,   0,   0,   2,   0,   1,   0,   2,  13, 166,   0,   0,   0,\n",
       "          0,   1,   0,   1,   0,   4,   0,   0,   0,   0,   3,   0,   2],\n",
       "       [  0,   1,   1,   2,   1,   0,   3,   3,   0,   0, 159,   0,   1,\n",
       "          0,   0,   0,   0,  11,   0,   0,   1,   0,   0,  10,   0,   0],\n",
       "       [  0,   0,   3,   2,   3,   0,   4,   2,   0,   0,   1, 166,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   3,   0,   1],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0, 178,\n",
       "          3,   2,   0,   0,   2,   0,   0,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,   1,   0,   7,   0,   0,   0,   7,   0,   0,   1,   0,   3,\n",
       "        189,   2,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  3,   0,   2,  10,   0,   0,   0,  14,   0,   0,   0,   0,   1,\n",
       "          0, 166,   3,   5,   0,   0,   0,   1,   0,   8,   0,   0,   0],\n",
       "       [  0,   1,   0,   2,   0,  10,   5,   0,   0,   0,   2,   0,   0,\n",
       "          0,   0, 169,   1,   0,   0,   0,   0,   1,   0,   0,   4,   0],\n",
       "       [  5,   1,   0,   1,   3,   0,  10,   0,   0,   0,   0,   0,   0,\n",
       "          0,   5,   0, 168,   0,  13,   0,   0,   1,   0,   0,   1,   0],\n",
       "       [  0,   5,   0,   2,   0,   0,   4,   3,   0,   0,   7,   0,   0,\n",
       "          2,   1,   0,   1, 142,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  10,   2,   0,   6,   3,   2,   0,   7,   1,   0,   2,   0,\n",
       "          0,   0,   0,   4,   0, 132,   0,   0,   0,   0,   2,   2,   8],\n",
       "       [  1,   1,   0,   0,   0,   4,   1,   2,   2,   0,   1,   0,   0,\n",
       "          0,   0,   1,   0,   1,   5, 169,   0,   0,   0,   1,   4,   3],\n",
       "       [  1,   0,   0,   0,   0,   0,   1,   5,   0,   0,   0,   0,   4,\n",
       "          2,   1,   0,   0,   0,   0,   2, 195,   0,   2,   0,   0,   0],\n",
       "       [  1,   5,   0,   0,   0,   0,   3,   4,   0,   0,   1,   0,   0,\n",
       "          2,   0,   2,   0,   1,   0,   0,   0, 160,   4,   0,   4,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  12,\n",
       "          0,   1,   0,   0,   1,   0,   0,   0,   2, 178,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   1,   1,   0,   3,   2,   7,   6,   0,\n",
       "          0,   0,   0,   0,   0,   2,   0,   0,   0,   0, 177,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   1,   2,   0,   0,   5,   0,   4,   0,   1, 163,   0],\n",
       "       [  0,   0,   0,   0,   4,   1,   0,   0,   2,   5,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,  19,   2,   0,   0,   0,   0,   0, 129]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a linear SVM model\n",
    "svm_linear = SVC(kernel='linear',probability=True)\n",
    "svm_linear.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_linear.predict(X_test)\n",
    "\n",
    "valuation('svm_linear', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_gaussian is: 0.9454\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0, 175,   0,   3,   2,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   6,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 151,   0,   5,   0,   4,   0,   0,   0,   0,   0,   0,\n",
       "          0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   8,   0, 195,   0,   0,   0,   5,   0,   0,   0,   0,   0,\n",
       "          3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   3,   1,   0, 180,   1,   6,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0,   2],\n",
       "       [  0,   1,   0,   0,   4, 196,   0,   0,   2,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   1,   2,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   5,   0,   0, 191,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   4,   0,   0,   0, 155,   0,   0,   3,   0,   0,\n",
       "          1,   1,   0,   2,   9,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   2,   0,   0,   1,   0, 172,   5,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  1,   0,   0,   2,   1,   1,   0,   0,   4, 179,   0,   0,   0,\n",
       "          0,   2,   0,   1,   0,   5,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   1,   1,   0,   0,   2,   0,   0, 175,   0,   1,\n",
       "          0,   0,   0,   0,  10,   0,   0,   0,   0,   0,   3,   0,   0],\n",
       "       [  0,   1,   0,   0,   1,   0,   4,   0,   0,   0,   0, 175,   0,\n",
       "          0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  1,   3,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0, 184,\n",
       "          1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   3,   0,   0,   0,   0,   1,\n",
       "        197,   9,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0, 207,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   1,   2,   9,   1,   1,   0,   0,   0,   0,   0,\n",
       "          0,   1, 178,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   1,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   4,   0, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          1,   0,   0,   0, 162,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   2,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1, 175,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  1,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   1, 187,   0,   0,   0,   3,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   2,\n",
       "          0,   0,   0,   0,   0,   0,   0, 207,   2,   1,   0,   0,   0],\n",
       "       [  0,   8,   0,   0,   0,   2,   1,   0,   0,   0,   0,   0,   0,\n",
       "          2,   0,   1,   0,   0,   0,   0,   0, 171,   0,   0,   2,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 190,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   1,   0,   0,   1,   0,   6,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   1,   0,   0,   0, 190,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0, 178,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   4,   0,   0,   0,   0,   0,   0, 156]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a gaussian SVM model\n",
    "svm_gaussian = SVC(kernel='rbf',probability=True)\n",
    "svm_gaussian.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_gaussian.predict(X_test)\n",
    "\n",
    "valuation('svm_gaussian', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_poly is: 0.8852\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[194,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   3,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0, 162,   0,   6,   1,   0,   2,   3,   0,   0,   0,   0,   0,\n",
       "          0,   8,   0,   0,   4,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   0, 137,   0,   5,   0,   5,   1,   0,   0,   0,   0,   0,\n",
       "          0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  1,   9,   0, 184,   0,   0,   0,   3,   0,   0,   0,   0,   0,\n",
       "          4,   8,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  0,   1,   2,   0, 177,   0,   7,   0,   0,   0,   0,   0,   0,\n",
       "          0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0],\n",
       "       [  0,   1,   0,   1,   4, 188,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,   2,   0,   0,   0,   4,   3,   0,   0,   0,   2,   0,   1],\n",
       "       [  0,   0,   2,   2,   1,   0, 170,   0,   0,   0,   1,   0,   0,\n",
       "          0,  20,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   2,   0,   3,   0,   1,   0, 117,   0,   0,   0,   0,   0,\n",
       "          0,  45,   0,   2,   7,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   1,   0,   1,   0,   0, 166,   3,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   0,   0,  11,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   1,   0,   0,   3, 178,   0,   0,   0,\n",
       "          0,   5,   0,   0,   0,   3,   0,   0,   0,   0,   6,   0,   0],\n",
       "       [  0,   0,   0,   1,   1,   0,   2,   7,   0,   0, 147,   0,   0,\n",
       "          0,   5,   0,   0,   9,   0,   0,   0,   0,   0,  21,   0,   0],\n",
       "       [  0,   2,   0,   0,   1,   0,   5,   3,   0,   0,   1, 167,   0,\n",
       "          0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   6,   0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,   5,   0,   0,   1,   0, 180,\n",
       "          1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   1,   0,   0,   0,   4,   0,   0,   0,   0,   0,\n",
       "        184,  19,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 208,   0,   1,   0,   0,   0,   0,   1,   1,   0,   0,   0],\n",
       "       [  0,   1,   0,   1,   1,   9,   4,   0,   0,   0,   0,   0,   0,\n",
       "          0,   2, 174,   2,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,  23,   0, 181,   1,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   1,   0,   0,\n",
       "          1,  12,   0,   0, 143,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "       [  0,   6,   0,   1,   1,   1,   1,   0,   0,   0,   0,   1,   0,\n",
       "          0,   5,   0,   0,   2, 155,   0,   0,   0,   0,   8,   0,   0],\n",
       "       [  1,   0,   0,   0,   1,   1,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   4,   0,   0,   1,   1, 179,   0,   0,   0,   4,   2,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   1,\n",
       "          0,  15,   0,   0,   1,   0,   0, 194,   0,   0,   0,   0,   0],\n",
       "       [  1,   2,   0,   0,   0,   1,   1,   2,   0,   0,   0,   0,   0,\n",
       "          0,   9,   1,   0,   0,   0,   0,   0, 168,   0,   0,   2,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "          0,   7,   0,   0,   0,   0,   0,   0,   3, 183,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   1,   5,   1,   0,\n",
       "          0,  29,   0,   0,   0,   0,   1,   1,   0,   0, 162,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,   1,   0,   2,   0,   0,   1,   0,   0,   0,   0, 173,   0],\n",
       "       [  0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   5,   0,   0,   0,   0,   0,   0, 155]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Polynomial SVM model\n",
    "svm_poly = SVC(kernel='poly',probability=True)\n",
    "svm_poly.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "valuation('svm_poly', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_sigmoid is: 0.4804\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Sigmoid SVM model\n",
    "svm_sigmoid = SVC(kernel='sigmoid',probability=True)\n",
    "svm_sigmoid.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_sigmoid.predict(X_test)\n",
    "\n",
    "valuation('svm_sigmoid', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC using PyKernels\n",
    "\n",
    "PyKernels is a python library for working with kernel methods in machine learning. It provides implementations of various kernel functions ranging from typical linear, polynomial or rbf ones through wawelet, fourier transformations, kernels for binary sequences and even kernels for labeled graphs.\n",
    "\n",
    "Below we will go through some of the other SVM kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Cossim Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_cos is: 0.4804\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a cossim SVM model\n",
    "from pykernels.regular import Cossim\n",
    "\n",
    "svm_cos = SVC(kernel = Cossim(),probability=True)\n",
    "svm_cos.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_cos.predict(X_test)\n",
    "\n",
    "valuation('svm_cos', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. InverseMultiquadratic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_mul is: 0.4804\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a InverseMultiquadratic SVM model\n",
    "from pykernels.regular import InverseMultiquadratic\n",
    "\n",
    "svm_mul = SVC(kernel = InverseMultiquadratic(),probability=True)\n",
    "svm_mul.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_mul.predict(X_test)\n",
    "\n",
    "valuation('svm_mul', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Laplacian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_lap is: 0.4804\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Laplacian SVM model\n",
    "from pykernels.regular import Laplacian\n",
    "\n",
    "svm_lap = SVC(kernel = Laplacian(),probability=True)\n",
    "svm_lap.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_lap.predict(X_test)\n",
    "\n",
    "valuation('svm_lap', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Log Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_log is: 0.4804\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a Log SVM model\n",
    "from pykernels.regular import Log\n",
    "\n",
    "svm_log= SVC(kernel = Log(),probability=True)\n",
    "svm_log.fit(X_train,y_train)\n",
    "y_pred = svm_log.predict(X_test)\n",
    "\n",
    "valuation('svm_log', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. TStudent Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_tst is: 0.9588\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a TStudent SVM model\n",
    "from pykernels.regular import TStudent\n",
    "\n",
    "svm_tst = SVC(kernel = TStudent(),probability=True)\n",
    "svm_tst.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_tst.predict(X_test)\n",
    "\n",
    "valuation('svm_tst', y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. ANOVA Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm_anova is: 0.9224\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[153,   0,   0,   1,   0,   0,   0,   3,   0,  19,   3,   6,   5,\n",
       "          0,   2,   0,   0,   1,   1,   0,   0,   0,   4,   0,   3,   0],\n",
       "       [  3, 109,   0,   3,   0,   0,   5,   8,  16,   6,   3,   1,   4,\n",
       "          0,   0,   4,   6,  10,   4,   0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,  98,   0,  27,   2,   5,   3,   0,   0,  10,   2,   1,\n",
       "          0,   0,   0,   1,   0,   2,   4,   0,   0,   7,   0,   0,   0],\n",
       "       [  8,  15,   0, 103,   0,   0,   1,  17,   7,  25,   1,   9,   4,\n",
       "          0,   3,   6,   0,   1,   7,   1,   0,   0,   0,   1,   0,   2],\n",
       "       [  0,   7,  35,   0,  87,   0,   3,   0,   5,   2,   4,  13,   1,\n",
       "          0,   0,   0,  10,   3,   7,   7,   2,   0,   2,   2,   2,   3],\n",
       "       [  0,  13,   0,   3,   2,  96,   6,   3,   1,   2,   0,   0,   0,\n",
       "          0,   0,  25,   1,   5,   7,  37,   0,   1,   5,   0,   0,   0],\n",
       "       [ 11,   1,  42,   1,   3,   2,  53,   5,   1,   1,   4,  20,   9,\n",
       "          0,   2,   0,  14,   8,  12,   0,   0,   0,   7,   2,   0,   0],\n",
       "       [  9,   1,   0,  11,   0,   2,   3,  43,   6,   4,   6,   2,  11,\n",
       "         24,  22,   2,   3,   7,   0,   5,   4,   1,   9,   1,   1,   0],\n",
       "       [  0,   2,   0,   3,   1,   4,   0,   5, 117,  18,   0,   6,   1,\n",
       "          0,   0,   2,   0,   7,   3,   0,   0,   0,   0,  11,   1,   3],\n",
       "       [ 62,   6,   0,   0,   0,  12,   0,   2,  15,  87,   0,   0,   1,\n",
       "          0,   0,   0,   3,   1,   3,   0,   1,   0,   0,   0,   0,   4],\n",
       "       [  3,   1,   6,   0,   9,   0,   7,   8,   2,   0,  88,  11,   8,\n",
       "          3,   2,   0,   4,  20,   0,   1,   7,   0,   7,   6,   0,   0],\n",
       "       [ 10,   1,   1,  13,   4,   0,  13,  11,   4,  11,   1,  94,   4,\n",
       "          0,   1,   0,   3,   0,   1,   0,   0,   0,   5,   3,   6,   0],\n",
       "       [ 15,   0,   0,   0,   0,   0,   0,  24,   0,   3,  11,   0, 119,\n",
       "          4,   1,   1,   0,   1,   0,   0,   0,   0,  11,   0,   0,   0],\n",
       "       [  3,   0,   1,   9,   0,   0,   1,  30,   0,   0,   1,   3,  38,\n",
       "         80,   6,   2,   0,   0,   0,   1,   2,   0,  34,   0,   2,   0],\n",
       "       [  9,   0,   1,  14,   0,   4,   7,  69,   3,  18,   0,   4,   3,\n",
       "          0,  54,   4,   5,   3,   0,   3,   3,   0,   9,   0,   0,   0],\n",
       "       [  0,   5,   0,   3,   0,  36,   4,   3,   1,   1,   2,   0,   2,\n",
       "          1,   2, 111,   0,   5,   2,   1,   0,   6,   9,   0,   1,   0],\n",
       "       [ 13,   2,   3,   0,   6,   0,   7,  17,   1,  11,   0,   5,   2,\n",
       "          0,   1,   1, 119,   0,   7,   0,   0,   3,   4,   0,   6,   0],\n",
       "       [  5,   9,   0,   2,   1,   0,   5,  14,   7,   4,   7,   4,   9,\n",
       "          0,   2,   0,   5,  84,   0,   0,   0,   0,   8,   1,   0,   0],\n",
       "       [  7,  18,   0,   0,   4,   6,   2,   0,  16,   9,   0,   8,   0,\n",
       "          0,   0,   3,   8,   0,  54,   6,   0,   0,   0,   5,   4,  31],\n",
       "       [  1,   0,   0,   0,   1,  35,   3,   0,   4,   0,   2,   0,   3,\n",
       "          1,   0,  16,   0,   4,   7,  77,   5,   9,   1,   1,  23,   3],\n",
       "       [  6,   0,   1,   1,   0,   1,   0,  22,   0,   0,   9,   4,  12,\n",
       "          5,   4,   0,   0,   0,   0,  11, 121,   0,  12,   0,   4,   0],\n",
       "       [  1,   1,   0,   0,   0,  12,   0,  18,   0,   0,   0,   0,   2,\n",
       "          0,   0,   3,   0,   0,   0,   2,   0,  98,  31,   0,  19,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   8,\n",
       "         11,   0,   4,   0,   1,   0,   1,   0,  16, 138,   0,   0,   0],\n",
       "       [  2,  14,   0,   3,   7,   0,   0,   4,  30,   9,   5,  11,   0,\n",
       "          0,   0,   0,   4,   2,  12,  10,   3,   0,   1,  77,   3,   4],\n",
       "       [  1,   0,   0,   1,   0,  26,   1,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   3,  10,   0,   5,  19,   2,  42,   5,   1,  57,   0],\n",
       "       [  5,   0,   2,   0,  15,   1,   0,   0,   4,   4,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,  31,   4,   0,   0,   0,  11,   0,  85]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a ANOVA SVM model\n",
    "from pykernels.regular import ANOVA\n",
    "\n",
    "svm_anova = SVC(kernel = ANOVA(),probability=True)\n",
    "svm_anova.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_anova.predict(X_test)\n",
    "\n",
    "valuation('svm_anova', y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracies of the Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of all Kernels use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_gaussian</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm_poly</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm_sigmoid</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_cos</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_mul</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_lap</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_log</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_tst</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm_anova</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kernel Name  Accuracy\n",
       "0    svm_linear    0.8496\n",
       "1  svm_gaussian    0.9454\n",
       "2      svm_poly    0.8852\n",
       "3   svm_sigmoid    0.4804\n",
       "4       svm_cos    0.4804\n",
       "5       svm_mul    0.4804\n",
       "6       svm_lap    0.4804\n",
       "7       svm_log    0.4804\n",
       "8       svm_tst    0.9588\n",
       "9     svm_anova    0.9224"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at Accuracies\n",
    "\n",
    "print('Accuracy of all Kernels use')\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_tst</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_gaussian</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm_anova</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm_poly</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm_sigmoid</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_cos</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_mul</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm_lap</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_log</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kernel Name  Accuracy\n",
       "8       svm_tst    0.9588\n",
       "1  svm_gaussian    0.9454\n",
       "9     svm_anova    0.9224\n",
       "2      svm_poly    0.8852\n",
       "0    svm_linear    0.8496\n",
       "3   svm_sigmoid    0.4804\n",
       "4       svm_cos    0.4804\n",
       "5       svm_mul    0.4804\n",
       "6       svm_lap    0.4804\n",
       "7       svm_log    0.4804"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorted Accuracy\n",
    "\n",
    "acc = acc.sort_values('Accuracy', ascending = False)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_tst</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kernel Name  Accuracy\n",
       "8     svm_tst    0.9588"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max Accuracy\n",
    "\n",
    "acc.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm_log</td>\n",
       "      <td>0.4804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kernel Name  Accuracy\n",
       "7     svm_log    0.4804"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Min Accuracy\n",
    "\n",
    "acc.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_tst</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_gaussian</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm_anova</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm_poly</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kernel Name  Accuracy\n",
       "8       svm_tst    0.9588\n",
       "1  svm_gaussian    0.9454\n",
       "9     svm_anova    0.9224\n",
       "2      svm_poly    0.8852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 4 Accuracies\n",
    "\n",
    "acc.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(acc['Kernel Name'], acc['Accuracy'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
